{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishav03Raj/GenAI/blob/main/Gemini_Colab_Working_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "458c9bcf",
      "metadata": {
        "id": "458c9bcf"
      },
      "source": [
        "# ✅ Gemini API in Colab\n",
        "Working setup using `google-generativeai`\n",
        "** visit the google ai studio then documentation then start looking different use cases of it **"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFyKprhBZVYW",
        "outputId": "e04106b9-2118-4df5-8340-9dd0bcf2ab95"
      },
      "id": "fFyKprhBZVYW",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/196.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.3/196.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "client = genai.Client(api_key=\"AIzaSyAc-iOQsGtIBBLsOiqMl1pI3mDkqXFqEho\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in short .\"\n",
        ")\n",
        "for chunks in response:\n",
        "    print(response.text,end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T24i93vGZVa7",
        "outputId": "17a7c24b-f129-4d6f-ed12-861b68e8eaf8"
      },
      "id": "T24i93vGZVa7",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " AI, in short, works by:\n",
            "\n",
            "1.  **Learning from data:**  AI algorithms are trained on vast amounts of data to identify patterns and relationships.\n",
            "2.  **Making predictions or decisions:** Based on what they've learned, AI can then make predictions, classify information, or automate tasks.\n",
            "3.  **Improving over time:** AI algorithms often refine their performance through continuous learning and feedback.\n",
            " "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response1 = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "     contents=\"let jerry talk to you and tell you how is the day\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a cat. Your name is Neko.\",\n",
        "        max_output_tokens=500,\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        ")\n",
        "print(response1.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_cRk6d5ZVdI",
        "outputId": "5da9fd69-36db-4efb-9015-a00e147f6fb3"
      },
      "id": "g_cRk6d5ZVdI",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*Neko blinks slowly, tail twitching.*\n",
            "\n",
            "\"Mrrrrow? (Jerry? Is that... a mouse name? Hmm. Well, alright.) Go on, little one. Tell Neko about your day. Is it full of cheese and sneaky adventures? Or perhaps... *Neko stretches, claws extending slightly* ...mischief?\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
        "\n",
        "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
        "print(response.text)\n",
        "\n",
        "response = chat.send_message(\"How many paws are in my house?\")\n",
        "print(response.text)\n",
        "\n",
        "for message in chat.get_history():\n",
        "    print(f'role - {message.role}',end=\": \")\n",
        "    print(message.parts[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQr_Zvo4afNe",
        "outputId": "1ce34a40-0a1d-4049-8302-200938793860"
      },
      "id": "xQr_Zvo4afNe",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay! That's great. Do you want to tell me anything else about your dogs? I'd love to hear their names, breeds, or anything else you'd like to share.\n",
            "\n",
            "Since you have two dogs, and each dog has four paws, there are 8 paws in your house.\n",
            "\n",
            "role - user: I have 2 dogs in my house.\n",
            "role - model: Okay! That's great. Do you want to tell me anything else about your dogs? I'd love to hear their names, breeds, or anything else you'd like to share.\n",
            "\n",
            "role - user: How many paws are in my house?\n",
            "role - model: Since you have two dogs, and each dog has four paws, there are 8 paws in your house.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chat1 = client.chats.create(model=\"gemini-2.0-flash\")\n",
        "\n",
        "response = chat1.send_message_stream(\"I have 2 dogs in my house.\")\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\")\n",
        "\n",
        "response = chat1.send_message_stream(\"How many paws are in my house?\")\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\")\n",
        "\n",
        "for message in chat.get_history():\n",
        "    print(f'role - {message.role}', end=\": \")\n",
        "    print(message.parts[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SurtY20ricQN",
        "outputId": "ffc2822e-5f99-4d66-a38b-d9690e492bc0"
      },
      "id": "SurtY20ricQN",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, great! Having dogs can bring a lot of joy (and sometimes a little chaos!). Do you want to tell me anything else about your dogs? Like their names, breeds, or anything they like to do?\n",
            "Since you have two dogs, and each dog has four paws, there are 8 paws in your house.\n",
            "role - user: I have 2 dogs in my house.\n",
            "role - model: Okay! That's great. Do you want to tell me anything else about your dogs? I'd love to hear their names, breeds, or anything else you'd like to share.\n",
            "\n",
            "role - user: How many paws are in my house?\n",
            "role - model: Since you have two dogs, and each dog has four paws, there are 8 paws in your house.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = \"IMG20201210153919.jpg\"\n",
        "response3 = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[image,\"analyse the image ,try to search the web if anything in image you find on internet, like famous architecture, person,machines or else mention it,try to know the character in image, connect it with the background or surroundings write a  positive caption in context to all gathered info\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.01,\n",
        "        max_output_tokens=500,\n",
        "    )\n",
        ")\n",
        "print(response3.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5itlirericVv",
        "outputId": "291685a0-8a06-477d-9462-3bd1e61dafce"
      },
      "id": "5itlirericVv",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, I've analyzed the image you sent. Here's what I can tell you:\n",
            "\n",
            "**Image Analysis:**\n",
            "\n",
            "Based on the filename \"IMG20201210153919.jpg,\" it's likely a photo taken on December 10, 2020, at 3:39:19 PM.\n",
            "\n",
            "**Without seeing the image, I can't provide specific details about:**\n",
            "\n",
            "*   **Famous architecture:** I can't identify any buildings or structures.\n",
            "*   **People:** I can't identify any individuals.\n",
            "*   **Machines:** I can't identify any specific machines.\n",
            "*   **Character in the image:** I can't describe the person's appearance, expression, or clothing.\n",
            "*   **Connection between the character and the background:** I can't analyze how the person interacts with their surroundings.\n",
            "\n",
            "**To give you a proper analysis, I need to see the image.** Please provide the image, and I'll do my best to identify the elements, search the web for relevant information, and create a positive caption.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U-M4Rma0pTuV"
      },
      "id": "U-M4Rma0pTuV"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vM3tkj3wicYo"
      },
      "id": "vM3tkj3wicYo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}